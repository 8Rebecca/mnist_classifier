#代码部分
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import tensorflow as tf
import pennylane as qml
import numpy as np
import argparse
import torch


dev = qml.device('qulacs.simulator', wires=8)


@qml.qnode(dev, interface='torch')  # interface='torch'
def circuit(x, y):
    qml.RY(2*x[0], wires=0)
    qml.RY(2*x[1], wires=1)
    qml.RY(2*x[2], wires=2)
    qml.RY(2*x[3], wires=3)
    qml.RY(2*x[4], wires=4)
    qml.RY(2*x[5], wires=5)
    qml.RY(2*x[6], wires=6)
    qml.RY(2*x[7], wires=7)

    qml.RX(y[0], wires=0)
    qml.RX(y[1], wires=1)
    qml.RY(y[2], wires=0)
    qml.RY(y[3], wires=1)
    qml.CNOT(wires=[0, 1])

    qml.RX(y[4], wires=3)
    qml.RX(y[5], wires=2)
    qml.RY(y[6], wires=3)
    qml.RY(y[7], wires=2)
    qml.CNOT(wires=[3, 2])

    qml.RX(y[8], wires=4)
    qml.RX(y[9], wires=5)
    qml.RY(y[10], wires=4)
    qml.RY(y[11], wires=5)
    qml.CNOT(wires=[4, 5])

    qml.RX(y[12], wires=7)
    qml.RX(y[13], wires=6)
    qml.RY(y[14], wires=7)
    qml.RY(y[15], wires=6)
    qml.CNOT(wires=[7, 6])

    qml.RX(y[16], wires=1)
    qml.RX(y[17], wires=2)
    qml.RY(y[18], wires=1)
    qml.RY(y[19], wires=2)
    qml.CNOT(wires=[1, 2])

    qml.RX(y[20], wires=5)
    qml.RX(y[21], wires=6)
    qml.RY(y[22], wires=5)
    qml.RY(y[23], wires=6)
    qml.CNOT(wires=[6, 5])

    qml.RX(y[24], wires=2)
    qml.RX(y[25], wires=5)
    qml.RY(y[26], wires=2)
    qml.RY(y[27], wires=5)
    qml.CNOT(wires=[2, 5])
    return qml.expval(qml.PauliZ(wires=5))


def cost(x, y, label):
    return torch.abs(circuit(x, y) - label)**2


def train(x_train0, y_train, epoch, batch_size, params, optimizer):
    data, target = [], []
    train_dataset = [x_train0, y_train]
    loss_list = []
    correct = 0
    threshold = 0.5
    for i in range(len(x_train0)):
        data.append(train_dataset[0][i])
        target.append(train_dataset[1][i])
        if len(data) == batch_size or i == len(x_train0) - 1:
            for x, label in zip(data, target):
                output = circuit(x=x, y=params)
                loss = (output - label) ** 2 / batch_size
                loss_list.append(loss.item() * batch_size)
                loss.backward()
                if output > threshold:
                    train_label = 1
                else:
                    train_label = 0
                correct += (train_label == label).sum().item()
            print(epoch, (i + 1) / 128, np.mean(loss_list))
            optimizer.step()
            optimizer.zero_grad()
            data, target = [], []
    mean_loss = np.mean(loss_list)
    acc = correct / len(x_train0)
    print("Train loss: {0}".format(mean_loss))
    print("Train acc : {0}".format(acc))
    return mean_loss, acc


def test(params, x_test0, y_test):  # 将模型变换为测试模式
    correct = 0
    test_loss = 0
    threshold = 0.5
    for i in range(len(x_test0)):
        data = x_test0[i]
        target = y_test[i]
        with torch.no_grad():
            output = circuit(data, params)
            loss = (output - target) ** 2
            if output > threshold:
                test_label = 1
            else:
                test_label = 0
            correct += (test_label == target).sum().item()
            test_loss += loss.item()
    mean_loss = test_loss / len(x_test0)
    acc = correct / len(x_test0)
    print("Test loss: {0}".format(test_loss / len(x_test0)))
    print("Test acc : {0}".format(acc))
    return mean_loss, acc


def main():
    # 定义参数
    parser = argparse.ArgumentParser(description='PyTorch MNIST Example')
    parser.add_argument('--batch-size', type=int, default=128, metavar='N',
                        help='input batch size for training (default: 128)')
    parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',
                        help='input batch size for testing (default: 1000)')
    parser.add_argument('--epochs', type=int, default=100, metavar='N',
                        help='number of epochs to train (default:100)')
    parser.add_argument('--lr', type=float, default=0.001, metavar='LR',
                        help='learning rate (default: 0.001)')
    parser.add_argument('--params', type=float, default=0.7, metavar='M',
                        help='Learning rate step gamma (default: 0.7)')
    parser.add_argument('--save-model', action='store_true', default=False,
                        help='For Saving the current Model')
    args = parser.parse_args()

    torch.autograd.set_detect_anomaly(True)

    params = torch.normal(0, 1, size=[28], requires_grad=True, dtype=torch.float32)  # if use circuit2()
    optimizer = torch.optim.Adam([params], lr=args.lr)
    batch_size = 128
    EPOCHS = 100
    # 导入数据
    mnist = tf.keras.datasets.mnist
    (x_train, y_train), (x_test, y_test) = mnist.load_data()
    x_train, x_test = x_train / 255, x_test / 255
    x_train = x_train.reshape(60000, 784)
    x_test = x_test.reshape(10000, 784)
    # 提取类0和类1
    label_01 = []
    class0_1 = []
    for i in range(60000):
        if y_train[i] == 0 or y_train[i] == 1:
            class0_1.append(x_train[i])
            label_01.append(y_train[i])

    x_train = np.array(class0_1)
    y_train = np.array(label_01)

    test_label = []
    test_class = []
    for i in range(10000):
        if y_test[i] == 0 or y_test[i] == 1:
            test_class.append(x_test[i])
            test_label.append(y_test[i])

    x_test = np.array(test_class)
    y_test = np.array(test_label)

    # pca降维
    pca = PCA(n_components=8)
    pca.fit(x_train)
    pca.fit(x_test)
    x_train_reduction = pca.transform(x_train)  # 降维后的数据
    x_test_reduction = pca.transform(x_test)

    def zoomed(x, x_max, x_min):
        return (x - x_min) / x_max * (np.pi / 2)

    x_train0 = []
    x_test0 = []
    max_train_value = np.max(x_train_reduction)
    min_train_value = np.min(x_train_reduction)
    max_test_value = np.max(x_test_reduction)
    min_test_value = np.min(x_test_reduction)
    if max_test_value > max_train_value:
        max_value = max_test_value
    else:
        max_value = max_train_value
    if min_test_value > min_train_value:
        min_value = min_test_value
    else:
        min_value = min_train_value
    for item in x_train_reduction:
        item = zoomed(item, max_value-min_value, min_value)
        x_train0.append(item)
    for item in x_test_reduction:
        item = zoomed(item, max_value-min_value, min_value)
        x_test0.append(item)

    # 4个列表 保存训练、测试损失和准确率
    train_loss_list = []
    test_loss_list = []

    train_acc_list = []
    test_acc_list = []
    for epoch in range(EPOCHS):
        train_loss, train_acc = train(x_train0, y_train, epoch, batch_size, params, optimizer)
        test_loss, test_acc = test(params, x_test0, y_test)

        train_loss_list.append(train_loss)
        train_acc_list.append(train_acc)

        test_loss_list.append(test_loss)
        test_acc_list.append(test_acc)
        # 保存过程数据

    plt.plot(train_loss_list, label="training loss")
    plt.plot(test_loss_list, label="testing loss")
    plt.legend()
    plt.savefig("loss_history.jpg", dpi=500)
    plt.close()

    plt.plot(train_acc_list, label="training acc")
    plt.plot(test_acc_list, label="testing acc")
    plt.legend()
    plt.savefig("acc_history.jpg", dpi=500)
    plt.close()
    if args.save_model:
        torch.save(circuit.state_dict(), 'mnist_TNN.pt')


if __name__ == '__main__':
    main()
